{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "mount_file_id": "1S1XenBhCMC_qXdZ50Jwgq709ZECzau7n",
   "authorship_tag": "ABX9TyMamt0hcytrrhg68DViNcVa"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# ===========================\n",
    "# Google Colab – Dataset Setup\n",
    "# ===========================\n",
    "\n",
    "# 1. Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Install kagglehub if not installed\n",
    "!pip install -q kagglehub\n",
    "\n",
    "# 3. Import\n",
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# 4. Download dataset from Kaggle\n",
    "print(\"Downloading dataset...\")\n",
    "source_path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
    "print(\"Downloaded to:\", source_path)\n",
    "\n",
    "# 5. Target path in your Drive\n",
    "target_path = \"/content/drive/MyDrive/brain_tumor_dataset\"\n",
    "\n",
    "# 6. Remove old folder if exists (optional)\n",
    "if os.path.exists(target_path):\n",
    "    print(\"Removing old dataset folder...\")\n",
    "    shutil.rmtree(target_path)\n",
    "\n",
    "# 7. Copy dataset to Drive\n",
    "print(\"Copying dataset to Google Drive...\")\n",
    "shutil.copytree(source_path, target_path)\n",
    "\n",
    "print(\"\\n✅ Dataset is ready at:\")\n",
    "print(target_path)\n"
   ],
   "metadata": {
    "id": "eagUL5rIaFFb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Mount Drive first\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# --- Removed steps 2, 3, 4, 5 (Download and Copy) as the dataset already exists ---\n",
    "\n",
    "# ---------------------------\n",
    "# CONFIG\n",
    "# ---------------------------\n",
    "DATA_ROOT = \"/content/drive/MyDrive/brain_tumor_dataset\"\n",
    "TRAIN_FOLDER = os.path.join(DATA_ROOT, \"Training\")\n",
    "TEST_FOLDER = os.path.join(DATA_ROOT, \"Testing\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "NUM_EPOCHS = 15\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "RANDOM_SEED = 42\n",
    "INPUT_SIZE = 224  # model input\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# UPDATED: Use a full path for the model save file\n",
    "MODEL_SAVE_PATH = \"/content/drive/MyDrive/brain_tumor_model_best.pth\"\n",
    "# UPDATED: Use a full path for the labels save file\n",
    "LABELS_SAVE = \"/content/drive/MyDrive/label_map.json\"\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset\n",
    "# ---------------------------\n",
    "class ImageFolderDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Simple dataset that expects folders per class:\n",
    "    root/class_x/xxx.png\n",
    "    root/class_y/yyy.png\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        classes = sorted([d.name for d in self.root_dir.iterdir() if d.is_dir()])\n",
    "        for idx, cls in enumerate(classes):\n",
    "            self.class_to_idx[cls] = idx\n",
    "            cls_dir = self.root_dir / cls\n",
    "            for p in cls_dir.iterdir():\n",
    "                if p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"]:\n",
    "                    self.samples.append((str(p), idx))\n",
    "        # sanity:\n",
    "        if len(self.samples) == 0:\n",
    "            raise RuntimeError(f\"No images found in {root_dir}. Check path and file extensions.\")\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, i):\n",
    "        path, label = self.samples[i]\n",
    "        # Open and convert to RGB (some MRIs might be grayscale)\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# ---------------------------\n",
    "# Transforms\n",
    "# ---------------------------\n",
    "train_transform = T.Compose([\n",
    "    T.RandomResizedCrop(INPUT_SIZE, scale=(0.8, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(15),\n",
    "    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers: model creation\n",
    "# ---------------------------\n",
    "def create_model(num_classes):\n",
    "    # Try EfficientNet_B0 if available, otherwise ResNet50\n",
    "    try:\n",
    "        # torchvision.models.efficientnet_b0 is available in newer torchvision\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        # Freeze all layers\n",
    "        # for param in model.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        # replace classifier\n",
    "        # EfficientNet has a sequential classifier; the final layer is index 1\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "        print(\"Using EfficientNet-B0\")\n",
    "    except Exception as e:\n",
    "        print(\"EfficientNet-B0 failed, falling back to ResNet50:\", e)\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        # Freeze all layers\n",
    "        # for param in model.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        # replace final fully connected layer\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        print(\"Using ResNet50\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# ---------------------------\n",
    "# Training / Validation loops\n",
    "# ---------------------------\n",
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(loader, desc=\"train\", leave=False):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    avg_loss = running_loss / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "def eval_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"eval\", leave=False):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy().tolist())\n",
    "            all_labels.extend(labels.cpu().numpy().tolist())\n",
    "    avg_loss = running_loss / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc, np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "# ---------------------------\n",
    "# Main training function\n",
    "# ---------------------------\n",
    "def main():\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "    # create dataset\n",
    "    try:\n",
    "        full_train_dataset = ImageFolderDataset(TRAIN_FOLDER, transform=train_transform)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"ERROR: Could not load data. Please check if {TRAIN_FOLDER} exists and contains images.\")\n",
    "        print(f\"Details: {e}\")\n",
    "        return\n",
    "\n",
    "    # save class map\n",
    "    class_to_idx = full_train_dataset.class_to_idx\n",
    "    # The keys in idx_to_class should be integers, so we cast them back.\n",
    "    idx_to_class = {str(v): k for k, v in class_to_idx.items()}\n",
    "    with open(LABELS_SAVE, \"w\") as f:\n",
    "        json.dump(idx_to_class, f, indent=2)\n",
    "    print(f\"Class map saved to: {LABELS_SAVE}\")\n",
    "    print(\"Classes:\", class_to_idx)\n",
    "    num_classes = len(class_to_idx)\n",
    "\n",
    "    # train/val split (e.g., 90/10)\n",
    "    n_total = len(full_train_dataset)\n",
    "    # Ensure there is at least 1 image in the validation set\n",
    "    n_val = max(1, int(0.10 * n_total))\n",
    "    n_train = n_total - n_val\n",
    "\n",
    "    # Make sure we have a valid split\n",
    "    if n_train <= 0:\n",
    "        print(\"ERROR: Not enough data for a train/validation split.\")\n",
    "        return\n",
    "\n",
    "    train_dataset, val_dataset = random_split(full_train_dataset, [n_train, n_val],\n",
    "                                              generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
    "\n",
    "    # A quirk of random_split: the transform needs to be set on the underlying dataset\n",
    "    # and we need a way to ensure the validation split uses the validation transform.\n",
    "    # The original approach is a common pattern but can be error-prone with DataLoaders.\n",
    "    # Let's create two separate dataset objects to ensure correct transforms are used.\n",
    "\n",
    "    # Re-initialize the validation dataset with the val_transform\n",
    "    # This is more robust than changing the transform on the shared underlying dataset\n",
    "    val_dataset_eval = ImageFolderDataset(TRAIN_FOLDER, transform=val_transform)\n",
    "    # Filter the evaluation dataset to only include the indices from the validation split\n",
    "    val_dataset_eval.samples = [val_dataset_eval.samples[i] for i in val_dataset.indices]\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    # Use the new val_dataset_eval for the loader\n",
    "    val_loader = DataLoader(val_dataset_eval, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "\n",
    "    model = create_model(num_classes).to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        print(f\"\\n=== Epoch {epoch}/{NUM_EPOCHS} ===\")\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "        val_loss, val_acc, val_preds, val_labels = eval_model(model, val_loader, criterion)\n",
    "        print(f\"Train loss: {train_loss:.4f}  acc: {train_acc:.4f}\")\n",
    "        print(f\"Val   loss: {val_loss:.4f}  acc: {val_acc:.4f}\")\n",
    "\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        # print classification report for this epoch\n",
    "        print(\"\\nVal classification report:\")\n",
    "        # Corrected: target_names from the idx_to_class map\n",
    "        sorted_class_names = [idx_to_class[str(i)] for i in range(num_classes)]\n",
    "        print(classification_report(val_labels, val_preds, target_names=sorted_class_names, zero_division=0))\n",
    "\n",
    "        # save best\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"class_to_idx\": class_to_idx,\n",
    "                \"input_size\": INPUT_SIZE\n",
    "            }, MODEL_SAVE_PATH)\n",
    "            print(f\"Saved best model to {MODEL_SAVE_PATH} (val_acc={best_val_acc:.4f})\")\n",
    "\n",
    "    # final evaluation on TEST_FOLDER (if provided)\n",
    "    if os.path.exists(TEST_FOLDER) and len(os.listdir(TEST_FOLDER)) > 0:\n",
    "        print(\"\\nRunning final evaluation on test set...\")\n",
    "        try:\n",
    "            test_dataset = ImageFolderDataset(TEST_FOLDER, transform=val_transform)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Could not load test data. Details: {e}\")\n",
    "            return\n",
    "\n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "        # Ensure the number of classes is consistent\n",
    "        if len(test_dataset.class_to_idx) != num_classes:\n",
    "            print(\"WARNING: Test set has a different number of classes than the training set.\")\n",
    "            # Proceed, but use the class names from the training set for the report\n",
    "\n",
    "        test_loss, test_acc, test_preds, test_labels = eval_model(model, test_loader, criterion)\n",
    "        print(f\"Test loss: {test_loss:.4f}  acc: {test_acc:.4f}\")\n",
    "        print(\"Test classification report:\")\n",
    "        # Use the training set class names for the report\n",
    "        print(classification_report(test_labels, test_preds, target_names=sorted_class_names, zero_division=0))\n",
    "    else:\n",
    "        print(f\"\\nSkipping test evaluation: {TEST_FOLDER} does not exist or is empty.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EnqtJ2qyL6yF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764531076206,
     "user_tz": -60,
     "elapsed": 1013823,
     "user": {
      "displayName": "magic Klai",
      "userId": "18344625219440744825"
     }
    },
    "outputId": "8b0efb31-d208-4159-ca97-8d9339e1ca1a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Class map saved to: /content/drive/MyDrive/label_map.json\n",
      "Classes: {'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using EfficientNet-B0\n",
      "\n",
      "=== Epoch 1/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.4342  acc: 0.8599\n",
      "Val   loss: 0.1566  acc: 0.9457\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.98      0.88      0.93       128\n",
      "  meningioma       0.87      0.92      0.89       129\n",
      "     notumor       0.96      1.00      0.98       149\n",
      "   pituitary       0.97      0.96      0.97       165\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Saved best model to /content/drive/MyDrive/brain_tumor_model_best.pth (val_acc=0.9457)\n",
      "\n",
      "=== Epoch 2/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.1641  acc: 0.9459\n",
      "Val   loss: 0.0879  acc: 0.9790\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.98      0.98      0.98       128\n",
      "  meningioma       0.96      0.97      0.97       129\n",
      "     notumor       0.98      1.00      0.99       149\n",
      "   pituitary       0.99      0.97      0.98       165\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Saved best model to /content/drive/MyDrive/brain_tumor_model_best.pth (val_acc=0.9790)\n",
      "\n",
      "=== Epoch 3/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.1011  acc: 0.9654\n",
      "Val   loss: 0.0559  acc: 0.9790\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.99      0.96      0.98       128\n",
      "  meningioma       0.94      0.98      0.96       129\n",
      "     notumor       0.99      1.00      1.00       149\n",
      "   pituitary       0.99      0.98      0.98       165\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "\n",
      "=== Epoch 4/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0751  acc: 0.9761\n",
      "Val   loss: 0.0370  acc: 0.9895\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.99      0.98      0.98       128\n",
      "  meningioma       0.96      0.99      0.98       129\n",
      "     notumor       1.00      1.00      1.00       149\n",
      "   pituitary       1.00      0.99      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Saved best model to /content/drive/MyDrive/brain_tumor_model_best.pth (val_acc=0.9895)\n",
      "\n",
      "=== Epoch 5/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0498  acc: 0.9823\n",
      "Val   loss: 0.0327  acc: 0.9912\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.99      0.99      0.99       128\n",
      "  meningioma       0.99      0.99      0.99       129\n",
      "     notumor       0.98      1.00      0.99       149\n",
      "   pituitary       1.00      0.98      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Saved best model to /content/drive/MyDrive/brain_tumor_model_best.pth (val_acc=0.9912)\n",
      "\n",
      "=== Epoch 6/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0436  acc: 0.9864\n",
      "Val   loss: 0.0191  acc: 0.9965\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.99      1.00       128\n",
      "  meningioma       0.98      1.00      0.99       129\n",
      "     notumor       1.00      1.00      1.00       149\n",
      "   pituitary       1.00      0.99      1.00       165\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Saved best model to /content/drive/MyDrive/brain_tumor_model_best.pth (val_acc=0.9965)\n",
      "\n",
      "=== Epoch 7/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0327  acc: 0.9914\n",
      "Val   loss: 0.0205  acc: 0.9965\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.99      1.00       128\n",
      "  meningioma       0.98      1.00      0.99       129\n",
      "     notumor       1.00      1.00      1.00       149\n",
      "   pituitary       1.00      0.99      1.00       165\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "\n",
      "=== Epoch 8/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0341  acc: 0.9905\n",
      "Val   loss: 0.0267  acc: 0.9895\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.99      1.00       128\n",
      "  meningioma       0.96      0.99      0.98       129\n",
      "     notumor       1.00      1.00      1.00       149\n",
      "   pituitary       0.99      0.98      0.98       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "=== Epoch 9/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0290  acc: 0.9911\n",
      "Val   loss: 0.0287  acc: 0.9895\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.98      0.99       128\n",
      "  meningioma       0.98      0.98      0.98       129\n",
      "     notumor       0.97      1.00      0.99       149\n",
      "   pituitary       1.00      0.99      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "=== Epoch 10/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0242  acc: 0.9928\n",
      "Val   loss: 0.0207  acc: 0.9895\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.98      0.99       128\n",
      "  meningioma       0.97      1.00      0.98       129\n",
      "     notumor       0.99      1.00      0.99       149\n",
      "   pituitary       1.00      0.98      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "=== Epoch 11/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0137  acc: 0.9959\n",
      "Val   loss: 0.0239  acc: 0.9930\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.98      0.99       128\n",
      "  meningioma       0.98      1.00      0.99       129\n",
      "     notumor       0.99      1.00      0.99       149\n",
      "   pituitary       1.00      0.99      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "=== Epoch 12/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0118  acc: 0.9971\n",
      "Val   loss: 0.0243  acc: 0.9912\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.99      1.00       128\n",
      "  meningioma       0.98      1.00      0.99       129\n",
      "     notumor       0.99      1.00      0.99       149\n",
      "   pituitary       1.00      0.98      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "=== Epoch 13/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0134  acc: 0.9951\n",
      "Val   loss: 0.0319  acc: 0.9877\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.99      0.99      0.99       128\n",
      "  meningioma       0.97      0.99      0.98       129\n",
      "     notumor       0.99      1.00      0.99       149\n",
      "   pituitary       1.00      0.97      0.98       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "=== Epoch 14/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0097  acc: 0.9975\n",
      "Val   loss: 0.0182  acc: 0.9930\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.98      0.99       128\n",
      "  meningioma       0.98      1.00      0.99       129\n",
      "     notumor       0.99      1.00      0.99       149\n",
      "   pituitary       1.00      0.99      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "=== Epoch 15/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0101  acc: 0.9969\n",
      "Val   loss: 0.0164  acc: 0.9947\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.99      1.00       128\n",
      "  meningioma       0.99      1.00      1.00       129\n",
      "     notumor       0.99      1.00      0.99       149\n",
      "   pituitary       1.00      0.99      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "Running final evaluation on test set...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                     "
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test loss: 0.0217  acc: 0.9954\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.99      0.99       300\n",
      "  meningioma       0.98      1.00      0.99       306\n",
      "     notumor       1.00      1.00      1.00       405\n",
      "   pituitary       1.00      0.99      0.99       300\n",
      "\n",
      "    accuracy                           1.00      1311\n",
      "   macro avg       1.00      1.00      1.00      1311\n",
      "weighted avg       1.00      1.00      1.00      1311\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r"
     ]
    }
   ]
  }
 ]
}
