{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "mount_file_id": "1S1XenBhCMC_qXdZ50Jwgq709ZECzau7n",
   "authorship_tag": "ABX9TyMamt0hcytrrhg68DViNcVa"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# ===========================\n",
    "# Google Colab – Dataset Setup\n",
    "# ===========================\n",
    "\n",
    "# 1. Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Install kagglehub if not installed\n",
    "!pip install -q kagglehub\n",
    "\n",
    "# 3. Import\n",
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# 4. Download dataset from Kaggle\n",
    "print(\"Downloading dataset...\")\n",
    "source_path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
    "print(\"Downloaded to:\", source_path)\n",
    "\n",
    "# 5. Target path in your Drive\n",
    "target_path = \"/content/drive/MyDrive/brain_tumor_dataset\"\n",
    "\n",
    "# 6. Remove old folder if exists (optional)\n",
    "if os.path.exists(target_path):\n",
    "    print(\"Removing old dataset folder...\")\n",
    "    shutil.rmtree(target_path)\n",
    "\n",
    "# 7. Copy dataset to Drive\n",
    "print(\"Copying dataset to Google Drive...\")\n",
    "shutil.copytree(source_path, target_path)\n",
    "\n",
    "print(\"\\n✅ Dataset is ready at:\")\n",
    "print(target_path)\n"
   ],
   "metadata": {
    "id": "eagUL5rIaFFb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "import os, json, random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DATA_ROOT = \"/content/drive/MyDrive/brain_tumor_dataset\"\n",
    "TRAIN_FOLDER = os.path.join(DATA_ROOT, \"Training\")\n",
    "TEST_FOLDER = os.path.join(DATA_ROOT, \"Testing\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "NUM_EPOCHS = 15\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "RANDOM_SEED = 42\n",
    "INPUT_SIZE = 224\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_SAVE_PATH = \"/content/drive/MyDrive/brain_tumor_model_best.pth\"\n",
    "LABELS_SAVE = \"/content/drive/MyDrive/label_map.json\"\n",
    "\n",
    "train_tf = T.Compose([\n",
    "    T.RandomResizedCrop(INPUT_SIZE, scale=(0.8, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(15),\n",
    "    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "val_tf = T.Compose([\n",
    "    T.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "def create_model(n):\n",
    "    \n",
    "    m = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "    m.classifier[1] = nn.Linear(m.classifier[1].in_features, n)\n",
    "    print(\"Using EfficientNet-B0\")\n",
    "    return m\n",
    "\n",
    "def run_epoch(model, loader, crit, opt=None):\n",
    "    train = opt is not None\n",
    "    model.train() if train else model.eval()\n",
    "    loss_sum, ok, total = 0, 0, 0\n",
    "    preds, labels = [], []\n",
    "\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for x, y in tqdm(loader, leave=False):\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            out = model(x)\n",
    "            loss = crit(out, y)\n",
    "\n",
    "            if train:\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "            loss_sum += loss.item() * x.size(0)\n",
    "            p = out.argmax(1)\n",
    "            ok += (p == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "            preds += p.cpu().numpy().tolist()\n",
    "            labels += y.cpu().numpy().tolist()\n",
    "\n",
    "    return loss_sum/total, ok/total, np.array(preds), np.array(labels)\n",
    "\n",
    "def main():\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "    full_ds = ImageFolder(TRAIN_FOLDER, transform=train_tf)\n",
    "    class_to_idx = full_ds.class_to_idx\n",
    "    idx_to_class = {str(v): k for k, v in class_to_idx.items()}\n",
    "\n",
    "    with open(LABELS_SAVE, \"w\") as f:\n",
    "        json.dump(idx_to_class, f)\n",
    "\n",
    "    n = len(full_ds)\n",
    "    n_val = max(1, int(0.1 * n))\n",
    "    n_train = n - n_val\n",
    "\n",
    "    train_ds, val_ds = random_split(\n",
    "        full_ds, [n_train, n_val],\n",
    "        generator=torch.Generator().manual_seed(RANDOM_SEED)\n",
    "    )\n",
    "\n",
    "    val_ds.dataset.transform = val_tf\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    model = create_model(len(class_to_idx)).to(DEVICE)\n",
    "\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='max', factor=0.5, patience=2)\n",
    "\n",
    "    best = 0\n",
    "    names = [idx_to_class[str(i)] for i in range(len(class_to_idx))]\n",
    "\n",
    "    for e in range(NUM_EPOCHS):\n",
    "        print(f\"\\nEpoch {e+1}/{NUM_EPOCHS}\")\n",
    "\n",
    "        tr_loss, tr_acc, _, _ = run_epoch(model, train_loader, crit, opt)\n",
    "        va_loss, va_acc, va_p, va_y = run_epoch(model, val_loader, crit)\n",
    "\n",
    "        print(f\"Train loss {tr_loss:.4f} acc {tr_acc:.4f}\")\n",
    "        print(f\"Val   loss {va_loss:.4f} acc {va_acc:.4f}\")\n",
    "\n",
    "        sched.step(va_acc)\n",
    "\n",
    "        print(classification_report(va_y, va_p, target_names=names, zero_division=0))\n",
    "\n",
    "        if va_acc > best:\n",
    "            best = va_acc\n",
    "            torch.save({\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"class_to_idx\": class_to_idx,\n",
    "                \"input_size\": INPUT_SIZE\n",
    "            }, MODEL_SAVE_PATH)\n",
    "            print(f\"Saved best model ({best:.4f})\")\n",
    "\n",
    "    if os.path.exists(TEST_FOLDER) and os.listdir(TEST_FOLDER):\n",
    "        test_ds = ImageFolder(TEST_FOLDER, transform=val_tf)\n",
    "        test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "        t_loss, t_acc, t_p, t_y = run_epoch(model, test_loader, crit)\n",
    "        print(f\"\\nTest loss {t_loss:.4f} acc {t_acc:.4f}\")\n",
    "        print(classification_report(t_y, t_p, target_names=names, zero_division=0))\n",
    "    else:\n",
    "        print(\"\\nSkipping test set\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EnqtJ2qyL6yF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764531076206,
     "user_tz": -60,
     "elapsed": 1013823,
     "user": {
      "displayName": "magic Klai",
      "userId": "18344625219440744825"
     }
    },
    "outputId": "8b0efb31-d208-4159-ca97-8d9339e1ca1a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Class map saved to: /content/drive/MyDrive/label_map.json\n",
      "Classes: {'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using EfficientNet-B0\n",
      "\n",
      "=== Epoch 1/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.4342  acc: 0.8599\n",
      "Val   loss: 0.1566  acc: 0.9457\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.98      0.88      0.93       128\n",
      "  meningioma       0.87      0.92      0.89       129\n",
      "     notumor       0.96      1.00      0.98       149\n",
      "   pituitary       0.97      0.96      0.97       165\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Saved best model to /content/drive/MyDrive/brain_tumor_model_best.pth (val_acc=0.9457)\n",
      "\n",
      "=== Epoch 2/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.1641  acc: 0.9459\n",
      "Val   loss: 0.0879  acc: 0.9790\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.98      0.98      0.98       128\n",
      "  meningioma       0.96      0.97      0.97       129\n",
      "     notumor       0.98      1.00      0.99       149\n",
      "   pituitary       0.99      0.97      0.98       165\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Saved best model to /content/drive/MyDrive/brain_tumor_model_best.pth (val_acc=0.9790)\n",
      "\n",
      "=== Epoch 3/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.1011  acc: 0.9654\n",
      "Val   loss: 0.0559  acc: 0.9790\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.99      0.96      0.98       128\n",
      "  meningioma       0.94      0.98      0.96       129\n",
      "     notumor       0.99      1.00      1.00       149\n",
      "   pituitary       0.99      0.98      0.98       165\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "\n",
      "=== Epoch 4/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0751  acc: 0.9761\n",
      "Val   loss: 0.0370  acc: 0.9895\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.99      0.98      0.98       128\n",
      "  meningioma       0.96      0.99      0.98       129\n",
      "     notumor       1.00      1.00      1.00       149\n",
      "   pituitary       1.00      0.99      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Saved best model to /content/drive/MyDrive/brain_tumor_model_best.pth (val_acc=0.9895)\n",
      "\n",
      "=== Epoch 5/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0498  acc: 0.9823\n",
      "Val   loss: 0.0327  acc: 0.9912\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.99      0.99      0.99       128\n",
      "  meningioma       0.99      0.99      0.99       129\n",
      "     notumor       0.98      1.00      0.99       149\n",
      "   pituitary       1.00      0.98      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Saved best model to /content/drive/MyDrive/brain_tumor_model_best.pth (val_acc=0.9912)\n",
      "\n",
      "=== Epoch 6/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0436  acc: 0.9864\n",
      "Val   loss: 0.0191  acc: 0.9965\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.99      1.00       128\n",
      "  meningioma       0.98      1.00      0.99       129\n",
      "     notumor       1.00      1.00      1.00       149\n",
      "   pituitary       1.00      0.99      1.00       165\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Saved best model to /content/drive/MyDrive/brain_tumor_model_best.pth (val_acc=0.9965)\n",
      "\n",
      "=== Epoch 7/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0327  acc: 0.9914\n",
      "Val   loss: 0.0205  acc: 0.9965\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.99      1.00       128\n",
      "  meningioma       0.98      1.00      0.99       129\n",
      "     notumor       1.00      1.00      1.00       149\n",
      "   pituitary       1.00      0.99      1.00       165\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "\n",
      "=== Epoch 8/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0341  acc: 0.9905\n",
      "Val   loss: 0.0267  acc: 0.9895\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.99      1.00       128\n",
      "  meningioma       0.96      0.99      0.98       129\n",
      "     notumor       1.00      1.00      1.00       149\n",
      "   pituitary       0.99      0.98      0.98       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "=== Epoch 9/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0290  acc: 0.9911\n",
      "Val   loss: 0.0287  acc: 0.9895\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.98      0.99       128\n",
      "  meningioma       0.98      0.98      0.98       129\n",
      "     notumor       0.97      1.00      0.99       149\n",
      "   pituitary       1.00      0.99      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "=== Epoch 10/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0242  acc: 0.9928\n",
      "Val   loss: 0.0207  acc: 0.9895\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.98      0.99       128\n",
      "  meningioma       0.97      1.00      0.98       129\n",
      "     notumor       0.99      1.00      0.99       149\n",
      "   pituitary       1.00      0.98      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "=== Epoch 11/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0137  acc: 0.9959\n",
      "Val   loss: 0.0239  acc: 0.9930\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.98      0.99       128\n",
      "  meningioma       0.98      1.00      0.99       129\n",
      "     notumor       0.99      1.00      0.99       149\n",
      "   pituitary       1.00      0.99      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "=== Epoch 12/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0118  acc: 0.9971\n",
      "Val   loss: 0.0243  acc: 0.9912\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.99      1.00       128\n",
      "  meningioma       0.98      1.00      0.99       129\n",
      "     notumor       0.99      1.00      0.99       149\n",
      "   pituitary       1.00      0.98      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "=== Epoch 13/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0134  acc: 0.9951\n",
      "Val   loss: 0.0319  acc: 0.9877\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.99      0.99      0.99       128\n",
      "  meningioma       0.97      0.99      0.98       129\n",
      "     notumor       0.99      1.00      0.99       149\n",
      "   pituitary       1.00      0.97      0.98       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "=== Epoch 14/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0097  acc: 0.9975\n",
      "Val   loss: 0.0182  acc: 0.9930\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.98      0.99       128\n",
      "  meningioma       0.98      1.00      0.99       129\n",
      "     notumor       0.99      1.00      0.99       149\n",
      "   pituitary       1.00      0.99      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "=== Epoch 15/15 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rtrain:   0%|          | 0/322 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loss: 0.0101  acc: 0.9969\n",
      "Val   loss: 0.0164  acc: 0.9947\n",
      "\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.99      1.00       128\n",
      "  meningioma       0.99      1.00      1.00       129\n",
      "     notumor       0.99      1.00      0.99       149\n",
      "   pituitary       1.00      0.99      0.99       165\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "\n",
      "Running final evaluation on test set...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                     "
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test loss: 0.0217  acc: 0.9954\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.99      0.99       300\n",
      "  meningioma       0.98      1.00      0.99       306\n",
      "     notumor       1.00      1.00      1.00       405\n",
      "   pituitary       1.00      0.99      0.99       300\n",
      "\n",
      "    accuracy                           1.00      1311\n",
      "   macro avg       1.00      1.00      1.00      1311\n",
      "weighted avg       1.00      1.00      1.00      1311\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r"
     ]
    }
   ]
  }
 ]
}
